{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2692d080-29aa-47f1-93d8-0ac4f14eab71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[START] Extraction (BASE_DIR=D:\\STUDY\\Software Lab\\Project\\scripts)\n",
      "[WARN] PDF not found: D:\\STUDY\\Software Lab\\Project\\scripts\\data\\raw_pdfs\\2016.pdf\n",
      "[WARN] PDF not found: D:\\STUDY\\Software Lab\\Project\\scripts\\data\\raw_pdfs\\2017.pdf\n",
      "[WARN] PDF not found: D:\\STUDY\\Software Lab\\Project\\scripts\\data\\raw_pdfs\\2018.pdf\n",
      "[WARN] PDF not found: D:\\STUDY\\Software Lab\\Project\\scripts\\data\\raw_pdfs\\2019.pdf\n",
      "[WARN] PDF not found: D:\\STUDY\\Software Lab\\Project\\scripts\\data\\raw_pdfs\\2020.pdf\n",
      "[WARN] PDF not found: D:\\STUDY\\Software Lab\\Project\\scripts\\data\\raw_pdfs\\2021.pdf\n",
      "[WARN] PDF not found: D:\\STUDY\\Software Lab\\Project\\scripts\\data\\raw_pdfs\\2022.pdf\n",
      "[WARN] PDF not found: D:\\STUDY\\Software Lab\\Project\\scripts\\data\\raw_pdfs\\2023.pdf\n",
      "[DONE] Extraction complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import pdfplumber, pandas as pd, csv\n",
    "import sys\n",
    "\n",
    "\n",
    "BASE_DIR = Path.cwd()\n",
    "\n",
    "RAW_DIR = BASE_DIR / 'data' / 'raw_pdfs'\n",
    "OUT_DIR = BASE_DIR / 'data' / 'extracted_csv'\n",
    "LOG = BASE_DIR / 'logs' / 'extraction.log'\n",
    "\n",
    "# Ensure dirs exist\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LOG.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "years = list(range(2016, 2024))  # inclusive: 2016..2023\n",
    "\n",
    "def log(msg):\n",
    "    with open(LOG, 'a', encoding='utf-8') as f:\n",
    "        f.write(msg + '\\n')\n",
    "    print(msg)\n",
    "\n",
    "log(f\"[START] Extraction (BASE_DIR={BASE_DIR})\")\n",
    "for y in years:\n",
    "    pdf_path = RAW_DIR / f\"{y}.pdf\"\n",
    "    if not pdf_path.exists():\n",
    "        log(f\"[WARN] PDF not found: {pdf_path}\")\n",
    "        continue\n",
    "\n",
    "    log(f\"[INFO] Processing {pdf_path.name}\")\n",
    "    rows = []\n",
    "    try:\n",
    "        with pdfplumber.open(str(pdf_path)) as doc:\n",
    "            for page_no, page in enumerate(doc.pages, start=1):\n",
    "                try:\n",
    "                    table = page.extract_table()\n",
    "                except Exception as e:\n",
    "                    log(f\"[ERROR] page {page_no} extract_table error: {e}\")\n",
    "                    continue\n",
    "                if not table:\n",
    "                    continue\n",
    "                # normalize each row's string cells\n",
    "                for r in table:\n",
    "                    rows.append([cell.strip() if isinstance(cell, str) else '' for cell in r])\n",
    "    except Exception as e:\n",
    "        log(f\"[ERROR] Failed to open {pdf_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "    if not rows:\n",
    "        log(f\"[WARN] No tables found in {pdf_path.name}\")\n",
    "        continue\n",
    "\n",
    "    # assume first non-empty row is header\n",
    "    header = rows[0]\n",
    "    data_rows = rows[1:]\n",
    "\n",
    "    # normalize header strings\n",
    "    header = [h if h is not None else '' for h in header]\n",
    "    header = [str(h).strip().lower().replace('\\n',' ').replace(' ','_') for h in header]\n",
    "\n",
    "    # build DataFrame (pad rows to header length)\n",
    "    cleaned = []\n",
    "    for r in data_rows:\n",
    "        if all((cell is None or str(cell).strip()=='') for cell in r):\n",
    "            continue\n",
    "        if len(r) < len(header):\n",
    "            r = r + [''] * (len(header) - len(r))\n",
    "        cleaned.append(r[:len(header)])\n",
    "\n",
    "    try:\n",
    "        df = pd.DataFrame(cleaned, columns=header)\n",
    "    except Exception as e:\n",
    "        log(f\"[ERROR] Could not create DataFrame for {y}: {e}\")\n",
    "        # fallback: save raw rows as CSV with generic columns\n",
    "        fallback_csv = OUT_DIR / f\"water_quality_{y}_raw.csv\"\n",
    "        with open(fallback_csv, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            for r in rows:\n",
    "                writer.writerow(r)\n",
    "        log(f\"[INFO] Wrote fallback raw CSV: {fallback_csv}\")\n",
    "        continue\n",
    "\n",
    "    out_csv = OUT_DIR / f\"water_quality_{y}.csv\"\n",
    "    df.to_csv(out_csv, index=False, encoding='utf-8')\n",
    "    log(f\"[INFO] Saved extracted CSV: {out_csv}\")\n",
    "\n",
    "log('[DONE] Extraction complete')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e12cd43-08f0-4256-b0ae-daa07cc1fd49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
